{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/examples/tensorflow/sentiment_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"numpy>=1.0.0,<2.0.0\" \"pandas>=1.0.0,<2.0.0\" \"matplotlib>=3.5.2,<3.6.0\" \"tensorflow>=2.0.0,<3.0.0\" shap==0.40.0\n",
    "! pip install -U \"mlfoundry>=0.4.2,<0.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize MLFoundry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import urllib.parse\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MlFoundry APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = client.create_run(project_name='tensorflow-project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove <br/> from input text\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "embedding_dim = 16\n",
    "epochs = 10\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    remove_dir = os.path.join(train_dir, 'unsup')\n",
    "    shutil.rmtree(remove_dir)\n",
    "\n",
    "\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "class MetricsLogCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mlf_run.log_metrics(logs)   # logging metrics using mlfoundry run\n",
    "\n",
    "\n",
    "def get_raw_dataset():\n",
    "    raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'aclImdb/train',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=seed)\n",
    "\n",
    "    raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'aclImdb/train',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=seed)\n",
    "\n",
    "    raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'aclImdb/test',\n",
    "        batch_size=batch_size)\n",
    "    return raw_train_ds, raw_val_ds, raw_test_ds\n",
    "\n",
    "\n",
    "def prep_dataset(raw_train_ds, raw_val_ds, raw_test_ds):\n",
    "    # Make a text-only dataset (without labels), then call adapt\n",
    "    train_text = raw_train_ds.map(lambda x, y: x)\n",
    "    vectorize_layer.adapt(train_text)\n",
    "\n",
    "    # retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "    text_batch, label_batch = next(iter(raw_train_ds))\n",
    "\n",
    "    train_ds = raw_train_ds.map(vectorize_text)\n",
    "    val_ds = raw_val_ds.map(vectorize_text)\n",
    "    test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def build_model(train_ds, val_ds, test_ds):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Embedding(max_features + 1, embedding_dim),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer='adam',\n",
    "                  metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=[MetricsLogCallback()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_exportable_model(model):\n",
    "    export_model = tf.keras.Sequential([\n",
    "        vectorize_layer,\n",
    "        model,\n",
    "        layers.Activation('sigmoid')\n",
    "    ])\n",
    "\n",
    "    export_model.compile(\n",
    "        loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    "    )\n",
    "    return export_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_val_ds, raw_test_ds = get_raw_dataset()\n",
    "train_ds, val_ds, test_ds = prep_dataset(raw_train_ds, raw_val_ds, raw_test_ds)\n",
    "model = build_model(train_ds, val_ds, test_ds)\n",
    "export_model = build_exportable_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loggable = {\n",
    "    'model': export_model,\n",
    "    'signatures': None,\n",
    "    'options': None\n",
    "}\n",
    "\n",
    "mlf_run.log_model(\n",
    "    name=\"sentiment-classifier\",\n",
    "    model=model_loggable,\n",
    "    framework=mlf.ModelFramework.TENSORFLOW,\n",
    "    description=\"example tensorflow model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28092292923bed62c8b687b499027e8fe5fa2d6eed1f342433a13f18841f982d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
