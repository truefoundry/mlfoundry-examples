{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJIteH9fR0BL",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/examples/huggingface_transformers/tweet_eval_emotion_text_classification.ipynb)\n",
    "\n",
    "**If you are running on Google Colab it is recommended to choose a GPU Runtime**\n",
    "\n",
    "**Runtime > Change Runtime Type > GPU**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-Gg-iNkR0BN",
    "tags": []
   },
   "source": [
    "# üèÉ‚Äç‚ôÇ TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWYiCaKKR0BO",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ü™Ñ MlFoundry can automatically log metrics and model checkpoints from HuggingFace Transformers ü§ó Trainer\n",
    "**Just attach the callback and let it do the rest!**\n",
    "\n",
    "```python\n",
    "# Make sure to login via `mlfoundry login` command or set API key in `MLF_API_KEY`\n",
    "# import os\n",
    "# os.environ.setdefault('MLF_API_KEY', '<your API key here>')\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from mlfoundry.integrations.transformers import MlFoundryTrainerCallback, LogModelStrategy\n",
    "\n",
    "mlf_cb = MlFoundryTrainerCallback(\n",
    "    project_name=\"huggingface\",\n",
    "    run_name=\"my-hf-run\",\n",
    "    flatten_params=True,\n",
    "    log_model_strategy=LogModelStrategy.BEST_PLUS_LATEST,\n",
    ")\n",
    "\n",
    "args = TrainingArguments(..., report_to=[])\n",
    "trainer = Trainer(..., args=args, callbacks=[mlf_cb])\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "**You can also create the callback from a pre initialised run**\n",
    "\n",
    "```python\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import mlfoundry as mlf\n",
    "from mlfoundry.integrations.transformers import MlFoundryTrainerCallback, LogModelStrategy\n",
    "\n",
    "client = mlf.get_client(api_key=\"...\")\n",
    "run = client.create_run(project_name=\"huggingface\", run_name=\"my-hf-run\")\n",
    "\n",
    "mlf_cb = MlFoundryTrainerCallback.from_run(\n",
    "    run=run,\n",
    "    auto_end_run=False,\n",
    "    flatten_params=True,\n",
    "    log_model_strategy=LogModelStrategy.BEST_PLUS_LATEST,\n",
    ")\n",
    "\n",
    "args = TrainingArguments(..., report_to=[])\n",
    "trainer = Trainer(..., args=args, callbacks=[mlf_cb])\n",
    "trainer.train()\n",
    "\n",
    "run.end()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFt8hpFSR0BO",
    "tags": []
   },
   "source": [
    "# üí™ Full example\n",
    "**To demonstrate we will finetune a small bert model on \"emotion\" subset of [Tweet Eval](https://huggingface.co/datasets/tweet_eval) dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHT56iepvJ5D",
    "tags": []
   },
   "source": [
    "## ‚¨áÔ∏è Install dependencies\n",
    "\n",
    "For torch, it is recommended to follow the instructions at https://pytorch.org/get-started/locally/  \n",
    "We will use the one already installed, otherwise we will just install the CPU version for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHSinaERR0BP"
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"numpy>=1.0.0,<2.0.0\" \"pandas>=1.0.0,<2.0.0\" scikit-learn \"tokenizers>=0.12.0,<1.0.0\" \"datasets>=2.2.1,<3.0.0\" \"transformers>=4.19.0,<5.0.0\"\n",
    "! pip install --quiet \"torch>=1.2.0,<2.0.0\"\n",
    "! pip install --quiet -U \"mlfoundry>=0.4.6,<0.5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2a3EqiQsjxb"
   },
   "outputs": [],
   "source": [
    "! pip freeze | grep 'torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku4pff7MR0BQ",
    "tags": []
   },
   "source": [
    "## üîë Login to MLFoundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-q6xYFaR0BR",
    "tags": []
   },
   "source": [
    "## üõ† Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48TsOZzltV7A"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import urllib.parse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import mlfoundry as mlf\n",
    "from mlfoundry.integrations.transformers import MlFoundryTrainerCallback, LogModelStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPFPQzXKR0BR",
    "tags": []
   },
   "source": [
    "### üì¶ Load the dataset and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSrRp35nta3J"
   },
   "outputs": [],
   "source": [
    "TASK = \"classification\"\n",
    "DATASET = \"tweet_eval\"\n",
    "SUBSET = \"emotion\"\n",
    "MODEL_CHECKPOINT = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "\n",
    "dataset = load_dataset(DATASET, SUBSET)\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R27eqx8ttc5k"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sdk10OfgtebL"
   },
   "outputs": [],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlUPnn2gxCjW"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, use_fast=True)\n",
    "tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PE56TPqxZL6"
   },
   "outputs": [],
   "source": [
    "sentence1_key, sentence2_key = \"text\", None\n",
    "if sentence2_key is None:\n",
    "    print(f\"Sentence: {dataset['train'][0][sentence1_key]}\")\n",
    "else:\n",
    "    print(f\"Sentence 1: {dataset['train'][0][sentence1_key]}\")\n",
    "    print(f\"Sentence 2: {dataset['train'][0][sentence2_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5TzllgnR0BT",
    "tags": []
   },
   "source": [
    "### ü§ñ Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJ8JDQMOxg_R"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True, max_length=256)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcnwvDTKxios"
   },
   "outputs": [],
   "source": [
    "preprocess_function(dataset['train'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "li8NDay4xm4X"
   },
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8aOqKDZR0BT",
    "tags": []
   },
   "source": [
    "### ‚öôÔ∏è Load the model checkpoint, setup training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpxUdw43gfwQ"
   },
   "outputs": [],
   "source": [
    "num_labels = dataset['train'].features['label'].num_classes\n",
    "labels = dataset['train'].features['label'].names\n",
    "label2id = dict(zip(labels, range(len(labels))))\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jv_P4tf3xs9z"
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_CHECKPOINT, label2id=label2id, id2label=id2label)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXyuBMg7xvJm"
   },
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model_name = MODEL_CHECKPOINT.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-{DATASET}-{SUBSET}-{TASK}\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    warmup_ratio=0.3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    push_to_hub=False,\n",
    "    report_to=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USYN36NzR0BU",
    "tags": []
   },
   "source": [
    "### ‚ö°Ô∏è Attach our callback and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7SsL7j_2ONw"
   },
   "outputs": [],
   "source": [
    "run = client.create_run(\n",
    "    project_name=f\"{DATASET}-{SUBSET}-{TASK}\".replace(\"_\", \"-\"),\n",
    "    run_name=f\"{model_name}-finetuned-hf\".replace(\"_\", \"-\")\n",
    ")\n",
    "mlf_cb = MlFoundryTrainerCallback.from_run(\n",
    "    run=run,\n",
    "    auto_end_run=False,\n",
    "    flatten_params=True,\n",
    "    log_model_strategy=LogModelStrategy.BEST_PLUS_LATEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtEZzWu0x1IY"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[mlf_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRWunNedx3fZ"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oGQ6H-OR0BU",
    "tags": []
   },
   "source": [
    "### ‚úèÔ∏è Note down the run id before we finish\n",
    "Don't worry you can get this anytime from https://app.truefoundry.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knjO4OPqR0BU"
   },
   "outputs": [],
   "source": [
    "RUN_FQN = run.fqn\n",
    "print(RUN_FQN) # fqn looks like \"<username>/<project_name>/<run_name>\"\n",
    "run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDwmeX3xYKYu"
   },
   "source": [
    "# ‚¨áÔ∏è Load the logged HuggingFace Transformers ü§ó model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJ1h5YPFYGoY"
   },
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "from mlfoundry.integrations.transformers import HF_MODEL_PATH\n",
    "from transformers import pipeline\n",
    "\n",
    "run = mlf.get_client().get_run(RUN_FQN)\n",
    "local_path = run.download_artifact(HF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sExU9vAAcw0c"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(local_path, use_fast=True)\n",
    "print(tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\"))\n",
    "      \n",
    "config = AutoConfig.from_pretrained(local_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_path, config=config)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqWFhYU9R0BU"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFec1HJ5UF-d"
   },
   "outputs": [],
   "source": [
    "classifier(\"Did we miss the fact that #BurkeRamsey swung &amp;hit his sister #JonBenet in the face with a golf club previously out of a fit of ?\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tweet_eval_emotion_text_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
