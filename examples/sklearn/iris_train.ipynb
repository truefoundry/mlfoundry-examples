{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:29:47.636 INFO    streamlit_gradio.networking: Hashes generated for all static assets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlfoundry as mlf\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_frame = pd.DataFrame(iris.data, columns = iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MlFoundry APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:31:27.780 INFO    mlfoundry.mlfoundry_api: Run is created with id acd8130866d646ba9a4e5ea113dacfd8 and name run_2022-03-14_22:31:27_utc\n"
     ]
    }
   ],
   "source": [
    "mlf_api = mlf.get_client() # to save locally\n",
    "mlf_run = mlf_api.create_run(project_name='sklearn-project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(iris_frame, data_slice=mlf.DataSlice.TRAIN)  # saves in parquet format\n",
    "mlf_run.log_dataset(iris_frame, data_slice=mlf.DataSlice.TEST, fileformat=mlf.FileFormat.CSV) # saves in csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Model Training\n",
    "clf = svm.SVC(gamma='scale', kernel='rbf', probability=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:31:29.714 INFO    mlfoundry.mlfoundry_run: Parameters logged successfully\n"
     ]
    }
   ],
   "source": [
    "params = {'classes': clf.classes_, 'features': clf.n_features_in_}\n",
    "mlf_run.log_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:31:34.490 INFO    mlfoundry.mlfoundry_run: Model logged Successfully\n"
     ]
    }
   ],
   "source": [
    "mlf_run.log_model(clf, mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Predictions Synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = clf.predict(X_train)\n",
    "y_hat_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:32:06.005 INFO    mlfoundry.mlfoundry_run: Metrics logged successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "metrics_dict = {}\n",
    "\n",
    "metrics_dict['accuracy_score'] = accuracy_score(y_test, y_hat_test)\n",
    "metrics_dict['f1_score'] = f1_score(y_test, y_hat_test, average='micro')\n",
    "\n",
    "mlf_run.log_metrics(metrics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the Dataset Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "2022-03-14 15:32:12.653 INFO    whylogs.app.config: No config file loaded\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "2022-03-14 15:32:12.707 INFO    mlfoundry.mlfoundry_run: Metrics logged successfully\n",
      "2022-03-14 15:32:12.710 INFO    mlfoundry.mlfoundry_run: Dataset stats have been successfully computed and logged\n",
      "2022-03-14 15:32:12.713 WARNING shap: Using 120 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Missing config\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d04a58fe9b44adb874d0ad848b397cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:32:12.787 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:12.811 INFO    shap: phi = [-0.01186082 -0.00678627 -0.28938475 -0.01532609]\n",
      "2022-03-14 15:32:12.812 INFO    shap: phi = [0.01860775 0.00662815 0.45994694 0.11093328]\n",
      "2022-03-14 15:32:12.814 INFO    shap: phi = [-6.74692326e-03  1.58113289e-04 -1.70562190e-01 -9.56071879e-02]\n",
      "2022-03-14 15:32:12.837 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:12.861 INFO    shap: phi = [0.01664889 0.01463432 0.56927224 0.0450056 ]\n",
      "2022-03-14 15:32:12.863 INFO    shap: phi = [-0.01811083 -0.00699037 -0.39424057  0.07716619]\n",
      "2022-03-14 15:32:12.865 INFO    shap: phi = [ 0.00146194 -0.00764395 -0.17503167 -0.1221718 ]\n",
      "2022-03-14 15:32:12.889 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:12.915 INFO    shap: phi = [-0.0100717   0.00157264 -0.27178825 -0.04247354]\n",
      "2022-03-14 15:32:12.916 INFO    shap: phi = [ 0.01220038  0.01409669 -0.15052694 -0.23148152]\n",
      "2022-03-14 15:32:12.918 INFO    shap: phi = [-0.00212868 -0.01566933  0.42231519  0.27395505]\n",
      "2022-03-14 15:32:12.939 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:12.962 INFO    shap: phi = [-0.01011337 -0.02167679 -0.27084094 -0.02245872]\n",
      "2022-03-14 15:32:12.964 INFO    shap: phi = [ 0.01843415 -0.01947586  0.46369559  0.06636973]\n",
      "2022-03-14 15:32:12.965 INFO    shap: phi = [-0.00832078  0.04115265 -0.19285464 -0.04391101]\n",
      "2022-03-14 15:32:12.987 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.011 INFO    shap: phi = [-0.00598617 -0.0097234  -0.26222565 -0.04379629]\n",
      "2022-03-14 15:32:13.013 INFO    shap: phi = [ 0.00255169  0.00584297 -0.02948273 -0.32293556]\n",
      "2022-03-14 15:32:13.014 INFO    shap: phi = [0.00343448 0.00388044 0.29170839 0.36673185]\n",
      "2022-03-14 15:32:13.037 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.061 INFO    shap: phi = [0.0242314  0.00546379 0.55378661 0.05364608]\n",
      "2022-03-14 15:32:13.063 INFO    shap: phi = [-0.02747235 -0.00229364 -0.37496202  0.06989725]\n",
      "2022-03-14 15:32:13.065 INFO    shap: phi = [ 0.00324095 -0.00317015 -0.17882459 -0.12354333]\n",
      "2022-03-14 15:32:13.090 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.114 INFO    shap: phi = [-0.01633158 -0.00209519 -0.26207986 -0.04202896]\n",
      "2022-03-14 15:32:13.115 INFO    shap: phi = [ 0.02125288  0.00998039 -0.18827818 -0.19888578]\n",
      "2022-03-14 15:32:13.116 INFO    shap: phi = [-0.0049213  -0.0078852   0.45035804  0.24091475]\n",
      "2022-03-14 15:32:13.139 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.164 INFO    shap: phi = [0.02807545 0.00621756 0.53699331 0.06029063]\n",
      "2022-03-14 15:32:13.165 INFO    shap: phi = [-0.03196752 -0.00305128 -0.35859957  0.06351285]\n",
      "2022-03-14 15:32:13.166 INFO    shap: phi = [ 0.00389208 -0.00316628 -0.17839374 -0.12380348]\n",
      "2022-03-14 15:32:13.188 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.211 INFO    shap: phi = [-0.00908805  0.0016539  -0.27610575 -0.03849755]\n",
      "2022-03-14 15:32:13.213 INFO    shap: phi = [ 0.00962574  0.01734513 -0.11616713 -0.26000927]\n",
      "2022-03-14 15:32:13.214 INFO    shap: phi = [-0.00053769 -0.01899902  0.39227288  0.29850682]\n",
      "2022-03-14 15:32:13.237 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.262 INFO    shap: phi = [0.01849858 0.01998847 0.56935124 0.04201972]\n",
      "2022-03-14 15:32:13.263 INFO    shap: phi = [-0.02089052 -0.00966017 -0.39467064  0.07930897]\n",
      "2022-03-14 15:32:13.265 INFO    shap: phi = [ 0.00239194 -0.0103283  -0.1746806  -0.12132869]\n",
      "2022-03-14 15:32:13.288 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.313 INFO    shap: phi = [-0.01432624 -0.00401958 -0.25930136 -0.04529439]\n",
      "2022-03-14 15:32:13.315 INFO    shap: phi = [ 0.01860296  0.00993242 -0.16039895 -0.22434035]\n",
      "2022-03-14 15:32:13.316 INFO    shap: phi = [-0.00427672 -0.00591284  0.41970031  0.26963474]\n",
      "2022-03-14 15:32:13.338 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.361 INFO    shap: phi = [-0.00624816 -0.00159592 -0.28995254 -0.02250292]\n",
      "2022-03-14 15:32:13.363 INFO    shap: phi = [ 0.00768851  0.02395059  0.25491567 -0.11181849]\n",
      "2022-03-14 15:32:13.364 INFO    shap: phi = [-0.00144035 -0.02235467  0.03503687  0.13432141]\n",
      "2022-03-14 15:32:13.387 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.410 INFO    shap: phi = [-0.0045538  -0.01808067 -0.28460556 -0.01359204]\n",
      "2022-03-14 15:32:13.411 INFO    shap: phi = [0.00089537 0.01137475 0.53430147 0.08297598]\n",
      "2022-03-14 15:32:13.413 INFO    shap: phi = [ 0.00365843  0.00670592 -0.24969591 -0.06938394]\n",
      "2022-03-14 15:32:13.436 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.460 INFO    shap: phi = [-0.01160351 -0.01111289 -0.26959685 -0.02968159]\n",
      "2022-03-14 15:32:13.462 INFO    shap: phi = [ 0.01365415 -0.00067555 -0.12811327 -0.20499583]\n",
      "2022-03-14 15:32:13.463 INFO    shap: phi = [-0.00205064  0.01178844  0.39771012  0.23467741]\n",
      "2022-03-14 15:32:13.485 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.509 INFO    shap: phi = [-0.01456183 -0.00598124 -0.25915818 -0.0418454 ]\n",
      "2022-03-14 15:32:13.510 INFO    shap: phi = [ 0.01828344  0.0102952  -0.0741715  -0.2948513 ]\n",
      "2022-03-14 15:32:13.511 INFO    shap: phi = [-0.00372162 -0.00431396  0.33332968  0.3366967 ]\n",
      "2022-03-14 15:32:13.533 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.557 INFO    shap: phi = [-0.00819011 -0.00512931 -0.28358992 -0.02374505]\n",
      "2022-03-14 15:32:13.558 INFO    shap: phi = [ 0.01218951  0.00470649  0.15010008 -0.15211213]\n",
      "2022-03-14 15:32:13.560 INFO    shap: phi = [-0.0039994   0.00042282  0.13348984  0.17585718]\n",
      "2022-03-14 15:32:13.583 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.606 INFO    shap: phi = [-0.01165546 -0.00950191 -0.26290618 -0.03954417]\n",
      "2022-03-14 15:32:13.608 INFO    shap: phi = [ 0.01486079  0.00540042 -0.17828934 -0.19729972]\n",
      "2022-03-14 15:32:13.609 INFO    shap: phi = [-0.00320532  0.0041015   0.44119552  0.23684389]\n",
      "2022-03-14 15:32:13.631 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.654 INFO    shap: phi = [-0.01536602 -0.00141084 -0.28586929 -0.01729693]\n",
      "2022-03-14 15:32:13.655 INFO    shap: phi = [0.02551368 0.01568752 0.42125228 0.09418995]\n",
      "2022-03-14 15:32:13.657 INFO    shap: phi = [-0.01014766 -0.01427668 -0.13538299 -0.07689302]\n",
      "2022-03-14 15:32:13.679 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.703 INFO    shap: phi = [ 0.00234286 -0.04690526 -0.25047386 -0.01560458]\n",
      "2022-03-14 15:32:13.705 INFO    shap: phi = [-0.01170491  0.03367446  0.50731869  0.08777258]\n",
      "2022-03-14 15:32:13.706 INFO    shap: phi = [ 0.00936205  0.01323079 -0.25684484 -0.072168  ]\n",
      "2022-03-14 15:32:13.729 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.753 INFO    shap: phi = [-0.02521244 -0.00569949 -0.24479919 -0.04373432]\n",
      "2022-03-14 15:32:13.755 INFO    shap: phi = [ 0.03141369  0.00510364 -0.27102464 -0.12246416]\n",
      "2022-03-14 15:32:13.756 INFO    shap: phi = [-0.00620125  0.00059585  0.51582383  0.16619848]\n",
      "2022-03-14 15:32:13.779 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.803 INFO    shap: phi = [-0.01160687 -0.00934757 -0.26638392 -0.03618105]\n",
      "2022-03-14 15:32:13.804 INFO    shap: phi = [ 0.01465878  0.00491205 -0.18714396 -0.18635383]\n",
      "2022-03-14 15:32:13.806 INFO    shap: phi = [-0.00305191  0.00443552  0.45352788  0.22253488]\n",
      "2022-03-14 15:32:13.829 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.853 INFO    shap: phi = [0.0103055  0.0371858  0.56028134 0.04199472]\n",
      "2022-03-14 15:32:13.854 INFO    shap: phi = [-0.01039405 -0.02095433 -0.39249679  0.07674659]\n",
      "2022-03-14 15:32:13.856 INFO    shap: phi = [ 8.85542387e-05 -1.62314739e-02 -1.67784548e-01 -1.18741306e-01]\n",
      "2022-03-14 15:32:13.880 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.904 INFO    shap: phi = [-0.00602897 -0.014677   -0.28650405 -0.01508317]\n",
      "2022-03-14 15:32:13.905 INFO    shap: phi = [0.0038211  0.00924698 0.5396903  0.07756631]\n",
      "2022-03-14 15:32:13.906 INFO    shap: phi = [ 0.00220787  0.00543002 -0.25318625 -0.06248314]\n",
      "2022-03-14 15:32:13.928 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:13.951 INFO    shap: phi = [0.0194116  0.0262973  0.55635589 0.04109503]\n",
      "2022-03-14 15:32:13.953 INFO    shap: phi = [-0.02120113 -0.01407521 -0.37617969  0.07075096]\n",
      "2022-03-14 15:32:13.954 INFO    shap: phi = [ 0.00178953 -0.01222208 -0.1801762  -0.11184599]\n",
      "2022-03-14 15:32:13.976 INFO    shap: num_full_subsets = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:32:14.004 INFO    shap: phi = [0.02435905 0.0190511  0.53925178 0.04957901]\n",
      "2022-03-14 15:32:14.005 INFO    shap: phi = [-0.02680524 -0.01095982 -0.35668498  0.06344874]\n",
      "2022-03-14 15:32:14.007 INFO    shap: phi = [ 0.0024462  -0.00809128 -0.1825668  -0.11302774]\n",
      "2022-03-14 15:32:14.030 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:14.053 INFO    shap: phi = [0.02113613 0.0162493  0.55619032 0.04968873]\n",
      "2022-03-14 15:32:14.054 INFO    shap: phi = [-0.02355404 -0.00857182 -0.38090714  0.07277155]\n",
      "2022-03-14 15:32:14.056 INFO    shap: phi = [ 0.00241791 -0.00767748 -0.17528318 -0.12246028]\n",
      "2022-03-14 15:32:14.078 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:14.109 INFO    shap: phi = [ 0.00672703 -0.05824542 -0.1581745  -0.02500913]\n",
      "2022-03-14 15:32:14.110 INFO    shap: phi = [-0.01425005  0.05654738  0.40318485  0.08331505]\n",
      "2022-03-14 15:32:14.112 INFO    shap: phi = [ 0.00752303  0.00169805 -0.24501035 -0.05830592]\n",
      "2022-03-14 15:32:14.134 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:14.157 INFO    shap: phi = [ 0.03137996 -0.02995453  0.5674116   0.04975688]\n",
      "2022-03-14 15:32:14.159 INFO    shap: phi = [-0.03903044  0.01762704 -0.36913326  0.07077359]\n",
      "2022-03-14 15:32:14.160 INFO    shap: phi = [ 0.00765048  0.01232749 -0.19827833 -0.12053047]\n",
      "2022-03-14 15:32:14.186 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:14.209 INFO    shap: phi = [-0.01895991 -0.00564105 -0.26068113 -0.03713314]\n",
      "2022-03-14 15:32:14.211 INFO    shap: phi = [ 0.02455796  0.00537074 -0.24817549 -0.13805922]\n",
      "2022-03-14 15:32:14.212 INFO    shap: phi = [-5.59804601e-03  2.70306755e-04  5.08856622e-01  1.75192362e-01]\n",
      "2022-03-14 15:32:14.233 INFO    shap: num_full_subsets = 2\n",
      "2022-03-14 15:32:14.258 INFO    shap: phi = [0.02395954 0.00707063 0.57955637 0.03886354]\n",
      "2022-03-14 15:32:14.259 INFO    shap: phi = [-0.03164261 -0.00226188 -0.39567821  0.08375823]\n",
      "2022-03-14 15:32:14.261 INFO    shap: phi = [ 0.00768307 -0.00480875 -0.18387816 -0.12262177]\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "2022-03-14 15:32:14.325 INFO    mlfoundry.mlfoundry_run: Metrics logged successfully\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "2022-03-14 15:32:14.345 INFO    mlfoundry.mlfoundry_run: Dataset stats have been successfully computed and logged\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "y_train_prob = clf.predict_proba(X_train)\n",
    "\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns=iris.feature_names)\n",
    "X_train_df['targets'] = y_train\n",
    "X_train_df['predictions'] = y_hat_train\n",
    "X_train_df['prediction_probabilities'] = list(y_train_prob)\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test, columns=iris.feature_names)\n",
    "X_test_df['targets'] = y_test\n",
    "X_test_df['predictions'] = y_hat_test\n",
    "\n",
    "# compute and log stats for train data without shap\n",
    "mlf_run.log_dataset_stats(\n",
    "    X_train_df, \n",
    "    data_slice=mlf.DataSlice.TRAIN,\n",
    "    data_schema=mlf.Schema(\n",
    "        feature_column_names=iris.feature_names,\n",
    "        prediction_column_name=\"predictions\",\n",
    "        actual_column_name=\"targets\",\n",
    "        prediction_probability_column_name=\"prediction_probabilities\"   # to calculate probability related metrics\n",
    "    ),\n",
    "    model_type=mlf.ModelType.MULTICLASS_CLASSIFICATION,\n",
    ")\n",
    "\n",
    "# shap value computation\n",
    "X_train_df1 = pd.DataFrame(X_train, columns=iris.feature_names)\n",
    "X_test_df1 = pd.DataFrame(X_test, columns=iris.feature_names)\n",
    "explainer = shap.KernelExplainer(clf.predict_proba, X_train_df1)\n",
    "shap_values = explainer.shap_values(X_test_df1)\n",
    "\n",
    "mlf_run.log_dataset_stats(\n",
    "    X_test_df, \n",
    "    data_slice=mlf.DataSlice.TEST,\n",
    "    data_schema=mlf.Schema(\n",
    "        feature_column_names=iris.feature_names,\n",
    "        prediction_column_name=\"predictions\",\n",
    "        actual_column_name=\"targets\"\n",
    "    ),\n",
    "    model_type=mlf.ModelType.MULTICLASS_CLASSIFICATION,\n",
    "    shap_values=shap_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:32:39.220 INFO    streamlit_gradio.networking: Hashes generated for all static assets.\n",
      "\u001b[32m\u001b[1mMlFoundry CLI\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.1.67:8502\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "2022-03-14 15:32:50.949 Hashes generated for all static assets.\n",
      "2022-03-14 15:32:52.728 Error in loading fpr, tpr. Error msg 'roc_curve'\n",
      "2022-03-14 15:32:52.733 Error in loading precision, recall. Error msg 'precision_recall_curve'\n",
      "2022-03-14 15:32:58.127 No config file loaded\n",
      "WARN: Missing config\n",
      "/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/model_view/data_health.py:22: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "\n",
      "2022-03-14 16:22:50.704 Error in loading fpr, tpr. Error msg 'roc_curve'\n",
      "2022-03-14 16:22:50.716 Error in loading precision, recall. Error msg 'precision_recall_curve'\n",
      "/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/model_view/data_health.py:22: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "\n",
      "/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/model_view/data_health.py:22: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "\n",
      "/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/model_view/data_health.py:22: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "\n",
      "2022-03-14 16:23:33.306 Artifact whylogs not found. Exception: No such file or directory: '/Users/cusgadmin/work/deepL/mlfoundry-examples/examples/sklearn/mlf/mlruns/5/630c30ded5b6482b914a55bf5e9cefc9/artifacts/whylogs'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/cache_utils.py\", line 126, in get_or_create_cached_value\n",
      "    return_value = cache.read_value(value_key)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 408, in read_value\n",
      "    raise e\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 401, in read_value\n",
      "    pickled_value = self._read_from_mem_cache(key)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 444, in _read_from_mem_cache\n",
      "    raise CacheKeyNotFoundError(\"Key not found in mem cache\")\n",
      "streamlit.caching.cache_errors.CacheKeyNotFoundError: Key not found in mem cache\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/cache_utils.py\", line 126, in get_or_create_cached_value\n",
      "    return_value = cache.read_value(value_key)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 408, in read_value\n",
      "    raise e\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 401, in read_value\n",
      "    pickled_value = self._read_from_mem_cache(key)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 444, in _read_from_mem_cache\n",
      "    raise CacheKeyNotFoundError(\"Key not found in mem cache\")\n",
      "streamlit.caching.cache_errors.CacheKeyNotFoundError: Key not found in mem cache\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/mlfoundry_data.py\", line 133, in get_artifact\n",
      "    return _self.mlflow_client.download_artifacts(run_id, artifact_name)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlflow/tracking/client.py\", line 1413, in download_artifacts\n",
      "    return self._tracking_client.download_artifacts(run_id, path, dst_path)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py\", line 391, in download_artifacts\n",
      "    return self._get_artifact_repo(run_id).download_artifacts(path, dst_path)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlflow/store/artifact/local_artifact_repo.py\", line 79, in download_artifacts\n",
      "    raise IOError(\"No such file or directory: '{}'\".format(local_artifact_path))\n",
      "OSError: No such file or directory: '/Users/cusgadmin/work/deepL/mlfoundry-examples/examples/sklearn/mlf/mlruns/5/630c30ded5b6482b914a55bf5e9cefc9/artifacts/whylogs'\n",
      "2022-03-14 16:23:35.446 Artifact stats not found. Exception: No such file or directory: '/Users/cusgadmin/work/deepL/mlfoundry-examples/examples/sklearn/mlf/mlruns/5/630c30ded5b6482b914a55bf5e9cefc9/artifacts/stats'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/cache_utils.py\", line 126, in get_or_create_cached_value\n",
      "    return_value = cache.read_value(value_key)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 408, in read_value\n",
      "    raise e\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 401, in read_value\n",
      "    pickled_value = self._read_from_mem_cache(key)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/streamlit/caching/memo_decorator.py\", line 444, in _read_from_mem_cache\n",
      "    raise CacheKeyNotFoundError(\"Key not found in mem cache\")\n",
      "streamlit.caching.cache_errors.CacheKeyNotFoundError: Key not found in mem cache\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/mlfoundry_data.py\", line 133, in get_artifact\n",
      "    return _self.mlflow_client.download_artifacts(run_id, artifact_name)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlflow/tracking/client.py\", line 1413, in download_artifacts\n",
      "    return self._tracking_client.download_artifacts(run_id, path, dst_path)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py\", line 391, in download_artifacts\n",
      "    return self._get_artifact_repo(run_id).download_artifacts(path, dst_path)\n",
      "  File \"/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlflow/store/artifact/local_artifact_repo.py\", line 79, in download_artifacts\n",
      "    raise IOError(\"No such file or directory: '{}'\".format(local_artifact_path))\n",
      "OSError: No such file or directory: '/Users/cusgadmin/work/deepL/mlfoundry-examples/examples/sklearn/mlf/mlruns/5/630c30ded5b6482b914a55bf5e9cefc9/artifacts/stats'\n",
      "2022-03-14 16:24:07.980 Error in loading fpr, tpr. Error msg 'roc_curve'\n",
      "2022-03-14 16:24:07.987 Error in loading precision, recall. Error msg 'precision_recall_curve'\n",
      "2022-03-14 16:24:22.002 Error in loading fpr, tpr. Error msg 'roc_curve'\n",
      "2022-03-14 16:24:22.009 Error in loading precision, recall. Error msg 'precision_recall_curve'\n",
      "/Users/cusgadmin/work/deepL/mlfoundry-examples/mlfexamples_env/lib/python3.9/site-packages/mlfoundry_ui/webapp/model_view/data_health.py:22: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mlfoundry ui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8743b0f75b6a55a016638ba229c0d478e77c985bb41c53d6f2fbe781d6f864f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
