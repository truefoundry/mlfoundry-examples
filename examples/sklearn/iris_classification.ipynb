{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/examples/sklearn/iris_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"numpy>=1.0.0,<2.0.0\" \"pandas>=1.0.0,<2.0.0\" \"matplotlib>=3.5.2,<3.6.0\" scikit-learn shap==0.40.0\n",
    "! pip install -U mlfoundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize MLFoundry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import urllib.parse\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFY_URL = os.environ.get('TFY_URL', 'https://app.truefoundry.com/')\n",
    "TFY_API_KEY = os.environ.get('TFY_API_KEY')\n",
    "if not TFY_API_KEY:\n",
    "    print(f'Paste your TrueFoundry API key\\nYou can find it over at {urllib.parse.urljoin(TFY_URL, \"settings\")}')\n",
    "    TFY_API_KEY = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlf.get_client(api_key=TFY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris plants detection as a Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris()\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame, first using the feature data\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# Add a target column, and fill it with the target data\n",
    "df['target'] = data.target\n",
    "# Show the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the feature data\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# store the target data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data using scikit-learn's train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)\n",
    "print('Train samples:', len(X_train))\n",
    "print('Test samples:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start MLFoundry Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.create_run(project_name='iris-project')\n",
    "print('RUN 1 ID:', run.run_id)\n",
    "print(f'You can track your runs live at {urllib.parse.urljoin(TFY_URL, \"mlfoundry\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='scale', kernel='rbf', probability=True)\n",
    "run.set_tags({'framework': 'sklearn', 'task': 'classification'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model, logging parameters and logging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(clf.get_params())\n",
    "run.log_params(clf.get_params())\n",
    "run.log_params({'classes': clf.classes_, 'features': clf.n_features_in_})\n",
    "run.log_model(clf, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging predictions\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'train/accuracy_score': accuracy_score(y_train, y_pred_train),\n",
    "    'train/f1': f1_score(y_train, y_pred_train, average='weighted'),\n",
    "    'test/accuracy_score': accuracy_score(y_test, y_pred_test),\n",
    "    'test/f1': f1_score(y_test, y_pred_test, average='weighted'),\n",
    "}\n",
    "print('Tree 1 metrics:', metrics)\n",
    "run.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='train',\n",
    "    features=X_train,\n",
    "    predictions=y_pred_train,\n",
    "    actuals=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='test',\n",
    "    features=X_test,\n",
    "    predictions=y_pred_test,\n",
    "    actuals=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(model=clf.predict_proba, data=X_train.copy(), link='logit')\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "X_train_df = X_train.copy()\n",
    "X_train_df['targets'] = list(y_train)\n",
    "X_train_df['predictions'] = list(y_pred_train)\n",
    "X_train_df['prediction_probabilities'] = list(clf.predict_proba(X_train))\n",
    "\n",
    "\n",
    "run.log_dataset_stats(\n",
    "    X_train_df, \n",
    "    data_slice='train',\n",
    "    data_schema=mlf.Schema(\n",
    "        feature_column_names=list(data.feature_names),\n",
    "        prediction_column_name='predictions',\n",
    "        actual_column_name='targets',\n",
    "        prediction_probability_column_name='prediction_probabilities'\n",
    "    ),\n",
    "    shap_values=shap_values,\n",
    "    model_type='multiclass_classification',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(model=clf.predict_proba, data=X_train.copy(), link='logit')\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "X_test_df = X_test.copy()\n",
    "X_test_df['targets'] = list(y_test)\n",
    "X_test_df['predictions'] = list(y_pred_test)\n",
    "X_test_df['prediction_probabilities'] = list(clf.predict_proba(X_test))\n",
    "\n",
    "run.log_dataset_stats(\n",
    "    X_test_df, \n",
    "    data_slice='test',\n",
    "    data_schema=mlf.Schema(\n",
    "        feature_column_names=list(data.feature_names),\n",
    "        prediction_column_name='predictions',\n",
    "        actual_column_name='targets',\n",
    "        prediction_probability_column_name='prediction_probabilities'\n",
    "    ),\n",
    "    shap_values=shap_values,\n",
    "    model_type='multiclass_classification',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.end()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32eca55f60ca0a4eb05caeb15f62cadd2ce358ded6aecd1922b0adda9a0225d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
