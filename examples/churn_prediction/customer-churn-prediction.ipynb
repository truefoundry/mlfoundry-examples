{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction 2020\n",
    "\n",
    "Public score: 0.98222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep mlfoundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "api_token = getpass(\"TrueFoundry API Token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T05:48:38.093464Z",
     "iopub.status.busy": "2022-05-11T05:48:38.092300Z",
     "iopub.status.idle": "2022-05-11T05:49:41.121215Z",
     "shell.execute_reply": "2022-05-11T05:49:41.119856Z",
     "shell.execute_reply.started": "2022-05-11T05:48:38.093416Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "mlf_api = mlf.get_client(api_key=api_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning the data \n",
    "* first calculate the total_net_minutes to reduce the number of features; we are going to do the same with calls, and charge \n",
    "* second we are going to convert all yes, no strings into ints such as in columns (voice_mail_plan, international_plan, and churn)\n",
    "* then we are going to convert the categorical values into onehote vectors such as (state, and area_code)\n",
    "* lastly drop all repeted features and useless columns such as area (code and state)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T05:31:45.411124Z",
     "iopub.status.busy": "2022-05-11T05:31:45.410821Z",
     "iopub.status.idle": "2022-05-11T05:31:45.418447Z",
     "shell.execute_reply": "2022-05-11T05:31:45.41731Z",
     "shell.execute_reply.started": "2022-05-11T05:31:45.41109Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_Data(df):    \n",
    "    df['total_net_minutes'] = df['total_day_minutes'] + df['total_eve_minutes'] + df['total_night_minutes']\n",
    "    df['total_net_calls'] = df['total_day_calls'] + df['total_eve_calls'] + df['total_night_calls']\n",
    "    df['total_net_charge'] = df['total_day_charge'] + df['total_eve_charge'] + df['total_night_charge']\n",
    "\n",
    "\n",
    "    df['voice_mail_plan'] = df['voice_mail_plan'].map({'yes': 1, 'no': 0}) \n",
    "    df['international_plan'] = df['international_plan'].map({'yes': 1, 'no': 0}) \n",
    "\n",
    "    df.drop(columns= ['state', 'area_code'], inplace= True)\n",
    "    #df.area_code = pd.Categorical(df.area_code).codes\n",
    "\n",
    "\n",
    "\n",
    "    df.drop(columns=['total_day_charge', 'total_eve_charge','total_night_charge',\n",
    "                    'total_day_calls','total_eve_calls', 'total_night_calls', 'total_day_minutes', \n",
    "                     'total_eve_minutes', 'total_night_minutes'], inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-11T04:34:30.103462Z",
     "iopub.status.idle": "2022-05-11T04:34:30.103827Z",
     "shell.execute_reply": "2022-05-11T04:34:30.10364Z",
     "shell.execute_reply.started": "2022-05-11T04:34:30.103618Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting the data \n",
    "* we are going to use sklearn to split the data \n",
    "* first we need to split the dataframe into x, y \n",
    "* then use train-test-spilt function to split the data \n",
    "* use random state to have same data each time you run the program \n",
    "* use stratify to cut the data with the same portion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-11T04:34:30.104974Z",
     "iopub.status.idle": "2022-05-11T04:34:30.105292Z",
     "shell.execute_reply": "2022-05-11T04:34:30.105143Z",
     "shell.execute_reply.started": "2022-05-11T04:34:30.105122Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = df.drop(columns= ['churn'])\n",
    "y = df['churn']\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y , test_size=.25, stratify= y, random_state=1) \n",
    "y_train.value_counts(), y_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preform the cleaing by calling the clean function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-11T04:34:30.106951Z",
     "iopub.status.idle": "2022-05-11T04:34:30.107258Z",
     "shell.execute_reply": "2022-05-11T04:34:30.107119Z",
     "shell.execute_reply.started": "2022-05-11T04:34:30.107098Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train  = clean_Data(x_train)\n",
    "y_train = pd.Categorical(y_train).codes\n",
    "\n",
    "x_val  = clean_Data(x_val)\n",
    "y_val= pd.Categorical(y_val).codes\n",
    "\n",
    "print(df.international_plan.value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# display all numerical columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:23:56.277081Z",
     "iopub.status.busy": "2022-05-11T01:23:56.276759Z",
     "iopub.status.idle": "2022-05-11T01:23:59.829837Z",
     "shell.execute_reply": "2022-05-11T01:23:59.829157Z",
     "shell.execute_reply.started": "2022-05-11T01:23:56.277025Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "sns.set_style('dark')\n",
    "temp = x_train[['account_length', 'international_plan','voice_mail_plan', 'number_vmail_messages', \n",
    "           'total_net_minutes','total_net_calls', 'total_net_charge','total_intl_minutes',\n",
    "       'total_intl_calls', 'total_intl_charge','number_customer_service_calls' ]]\n",
    "temp.hist(bins=50,figsize=(20,20),color='navy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create some models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first we start with simple model such as LogisticRegression \n",
    "* it preform well but not the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:23:59.831911Z",
     "iopub.status.busy": "2022-05-11T01:23:59.831247Z",
     "iopub.status.idle": "2022-05-11T01:24:00.092034Z",
     "shell.execute_reply": "2022-05-11T01:24:00.091158Z",
     "shell.execute_reply.started": "2022-05-11T01:23:59.831878Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr  = LogisticRegression(max_iter=300,)\n",
    "lr .fit(x_train,y_train )\n",
    "lr .score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:00.093926Z",
     "iopub.status.busy": "2022-05-11T01:24:00.093354Z",
     "iopub.status.idle": "2022-05-11T01:24:00.111249Z",
     "shell.execute_reply": "2022-05-11T01:24:00.110416Z",
     "shell.execute_reply.started": "2022-05-11T01:24:00.093879Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = lr .predict(x_val)\n",
    "score = [i for i, j in zip(pre, y_val) if i == j]\n",
    "\n",
    "score = len(score)/len(y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-kaggle-project', run_name='logistic-regression')\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'raw_dataset',\n",
    "    features = df,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train',\n",
    "    features = x_train,\n",
    "    predictions = lr.predict(x_train),\n",
    "    actuals = y_train,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val',\n",
    "    features = x_val,\n",
    "    predictions = lr.predict(x_val),\n",
    "    actuals = y_val,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "\n",
    "mlf_run.log_metrics({'score': score})\n",
    "mlf_run.log_model(lr, framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(lr.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frist we start with RandomForestClassifier \n",
    "**then we use the random forest classifier** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:00.114487Z",
     "iopub.status.busy": "2022-05-11T01:24:00.113865Z",
     "iopub.status.idle": "2022-05-11T01:24:00.895661Z",
     "shell.execute_reply": "2022-05-11T01:24:00.894637Z",
     "shell.execute_reply.started": "2022-05-11T01:24:00.114441Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train,y_train )\n",
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x_val.head(1).to_json()\n",
    "p_df = pd.read_json(p)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_predict():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:00.896989Z",
     "iopub.status.busy": "2022-05-11T01:24:00.896774Z",
     "iopub.status.idle": "2022-05-11T01:24:00.935989Z",
     "shell.execute_reply": "2022-05-11T01:24:00.935208Z",
     "shell.execute_reply.started": "2022-05-11T01:24:00.896963Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = clf.predict(x_val)\n",
    "score = [i for i, j in zip(pre, y_val) if i == j]\n",
    "\n",
    "score = len(score)/len(y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-kaggle-project', run_name='random-forest')\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'raw_dataset',\n",
    "    features = df,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train',\n",
    "    features = x_train,\n",
    "    predictions = lr.predict(x_train),\n",
    "    actuals = y_train,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val',\n",
    "    features = x_val,\n",
    "    predictions = lr.predict(x_val),\n",
    "    actuals = y_val,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "\n",
    "mlf_run.log_metrics({'score': score})\n",
    "mlf_run.log_model(clf, framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(clf.get_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lasly we used  GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:00.937713Z",
     "iopub.status.busy": "2022-05-11T01:24:00.937494Z",
     "iopub.status.idle": "2022-05-11T01:24:11.403089Z",
     "shell.execute_reply": "2022-05-11T01:24:11.40229Z",
     "shell.execute_reply.started": "2022-05-11T01:24:00.937687Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "xg = GradientBoostingClassifier(learning_rate=0.01, n_estimators=400,max_depth=13)\n",
    "xg.fit(x_train,y_train )\n",
    "xg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:11.40525Z",
     "iopub.status.busy": "2022-05-11T01:24:11.404578Z",
     "iopub.status.idle": "2022-05-11T01:24:11.442948Z",
     "shell.execute_reply": "2022-05-11T01:24:11.442103Z",
     "shell.execute_reply.started": "2022-05-11T01:24:11.405208Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = xg.predict(x_val)\n",
    "score = [i for i, j in zip(pre, y_val) if i == j]\n",
    "\n",
    "score = len(score)/len(y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-kaggle-project', run_name='xgboost')\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'raw_dataset',\n",
    "    features = df,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train',\n",
    "    features = x_train,\n",
    "    predictions = lr.predict(x_train),\n",
    "    actuals = y_train,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val',\n",
    "    features = x_val,\n",
    "    predictions = lr.predict(x_val),\n",
    "    actuals = y_val,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "\n",
    "mlf_run.log_metrics({'score': score})\n",
    "mlf_run.log_model(xg, framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(xg.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, lr.predict(x_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:11.444374Z",
     "iopub.status.busy": "2022-05-11T01:24:11.444149Z",
     "iopub.status.idle": "2022-05-11T01:24:11.460569Z",
     "shell.execute_reply": "2022-05-11T01:24:11.459998Z",
     "shell.execute_reply.started": "2022-05-11T01:24:11.444349Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "x_test =test.drop(columns='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test cleaning \n",
    "**clean the test data using the same function we used for train data cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:11.462437Z",
     "iopub.status.busy": "2022-05-11T01:24:11.461955Z",
     "iopub.status.idle": "2022-05-11T01:24:11.484807Z",
     "shell.execute_reply": "2022-05-11T01:24:11.48392Z",
     "shell.execute_reply.started": "2022-05-11T01:24:11.462393Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = clean_Data(x_test)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use model to predict the values \n",
    "## first use the xg boost to predict the test values \n",
    "After we use the model to predict the data we save the values in csv file to use in the submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:11.488211Z",
     "iopub.status.busy": "2022-05-11T01:24:11.48771Z",
     "iopub.status.idle": "2022-05-11T01:24:11.537049Z",
     "shell.execute_reply": "2022-05-11T01:24:11.536369Z",
     "shell.execute_reply.started": "2022-05-11T01:24:11.488168Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = xg.predict(x_test)\n",
    "print(pre[:5])\n",
    "ansXG = pd.read_csv('../input/customer-churn-prediction-2020/sampleSubmission.csv')\n",
    "ansXG.churn = pre\n",
    "ansXG.churn= ansXG.churn.map({ 1: 'yes', 0 : 'no'}) \n",
    "ansXG.to_csv('sampleSubmissionXG.csv', index=False)\n",
    "ansXG.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## then use the randomforest \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:11.538738Z",
     "iopub.status.busy": "2022-05-11T01:24:11.538334Z",
     "iopub.status.idle": "2022-05-11T01:24:11.585541Z",
     "shell.execute_reply": "2022-05-11T01:24:11.584999Z",
     "shell.execute_reply.started": "2022-05-11T01:24:11.538695Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = clf.predict(x_test)\n",
    "print(pre[:5])\n",
    "ansCLF = pd.read_csv('../input/customer-churn-prediction-2020/sampleSubmission.csv')\n",
    "ansCLF.churn = pre\n",
    "ansCLF.churn= ansCLF.churn.map({ 1: 'yes', 0 : 'no'}) \n",
    "ansCLF.to_csv('sampleSubmissionCLF.csv', index=False)\n",
    "ansCLF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to check which one will be better for the data but both have the same accuracy value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model saving\n",
    "Using joblib to dump the models into joblib files with the model name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T01:24:11.587159Z",
     "iopub.status.busy": "2022-05-11T01:24:11.586771Z",
     "iopub.status.idle": "2022-05-11T01:24:11.757911Z",
     "shell.execute_reply": "2022-05-11T01:24:11.757283Z",
     "shell.execute_reply.started": "2022-05-11T01:24:11.58713Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(clf, 'clf.joblib') \n",
    "dump(xg, 'xg.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
