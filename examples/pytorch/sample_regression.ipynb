{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/examples/pytorch/sample_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample regression with PyTorch\n",
    "\n",
    "In this notebook we fit a simple Pytorch neural network model to randomly generated data for a regression problem. We will use MLFoundry (by TrueFoundry) to track our experiment run and log important hyperparameters and metrics which can later be viewed at https://app.truefoundry.com/mlfoundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "\n",
    "For torch, it is recommended to follow the instructions at https://pytorch.org/get-started/locally/  \n",
    "We will use the one already installed, otherwise we will just install the CPU version for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install 'numpy>=1.0.0,<2.0.0' 'pandas>=1.0.0,<2.0.0' 'matplotlib>=3.5.2,<3.6.0' scikit-learn shap==0.40.0\n",
    "! pip install 'torch>=1.2.0,<2.0.0'\n",
    "! pip install -U mlfoundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize MLFoundry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import urllib.parse\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLF_API_KEY = os.environ.get('MLF_API_KEY')\n",
    "if not MLF_API_KEY:\n",
    "    print(\"Please get your API key from https://app.truefoundry.com/settings\")\n",
    "    MLF_API_KEY = getpass.getpass(\"Paste your API key and hit enter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlf.get_client(api_key=MLF_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed_value: int, cuda: bool = False):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "For this example, we will generate dummy data\n",
    "Our input feature would be a single float and \n",
    "Our target would be square of the input. We'll add some noise to our training data outputs to simulate noise observed while real world data collection.\n",
    "\n",
    "In short our regression model to should learn the power function within the input domain of [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2022)\n",
    "X = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1)  # shape=(100, 1)\n",
    "y = X.pow(2) + 0.2 * torch.rand(X.size())               # noisy y, shape=(100, 1)\n",
    "\n",
    "# convert to torch.Variable for training\n",
    "X, y = Variable(X), Variable(y)\n",
    "\n",
    "X_test = torch.rand(100, 1)  \n",
    "y_test = X.pow(2)        \n",
    "\n",
    "# visualize data\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.scatter(X.data.numpy(), y.data.numpy(), color='orange')\n",
    "plt.title('Regression Analysis')\n",
    "plt.xlabel('Independent varible')\n",
    "plt.ylabel('Dependent varible')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model\n",
    "\n",
    "We will use a simple Neural network with one hidden layer with ReLU as the activation function.\n",
    "We will use Mean Squared Error Loss as we are dealing with a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.output = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.output(x)             # linear output\n",
    "        return x\n",
    "\n",
    "\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "Here we pass in a MLFoundry run instance and log our hyperparameters and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, lr, hidden, run, seed=2022):\n",
    "    set_random_seed(seed)\n",
    "    \n",
    "    # Log important hyperparameters\n",
    "    params = {\n",
    "        'epoch': epoch,\n",
    "        'lr': lr,\n",
    "        'hidden': hidden,\n",
    "        'seed': seed\n",
    "    }\n",
    "    run.log_params(params)\n",
    "    \n",
    "    \n",
    "    net = Net(n_feature=1, n_hidden=hidden, n_output=1)     # define the network\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "    for t in range(epoch):\n",
    "        net.train()\n",
    "        prediction = net(X)     # input x and predict based on x\n",
    "        loss = loss_func(prediction, y)\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "\n",
    "        \n",
    "        # Get predictions on test data\n",
    "        net.eval()\n",
    "        y_true = y_test.detach().numpy()\n",
    "        y_true = np.reshape(y_true, y_true.shape[0])\n",
    "        y_pred = net(X_test).detach().numpy()\n",
    "        y_pred = np.reshape(y_pred, y_pred.shape[0])\n",
    "\n",
    "        # Compute Metrics\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        # Log them with the run\n",
    "        run.log_metrics({'mean absolute error': mae, 'mean squared error': mse})\n",
    "\n",
    "        # plot and show learning process\n",
    "        plt.cla()\n",
    "        ax.set_title('Regression Analysis', fontsize=35)\n",
    "        ax.set_xlabel('Independent variable', fontsize=24)\n",
    "        ax.set_ylabel('Dependent variable', fontsize=24)\n",
    "        ax.set_xlim(-1.05, 1.5)\n",
    "        ax.set_ylim(-0.25, 1.25)\n",
    "        ax.scatter(X.data.numpy(), y.data.numpy(), color='orange')\n",
    "        ax.plot(X.data.numpy(), prediction.data.numpy(), 'g-', lw=3)\n",
    "        ax.text(1.0, 0.1, 'Step = %d' % t, fontdict={'size': 24, 'color': 'red'})\n",
    "        ax.text(1.0, 0, 'Loss = %.4f' % loss.data.numpy(), fontdict={'size': 24, 'color': 'red'})\n",
    "\n",
    "        fig.canvas.draw()  \n",
    "        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.create_run(project_name='pytorch-sample-regression')\n",
    "print('RUN ID:', run.run_id)\n",
    "print(f'You can track your runs live at {urllib.parse.urljoin(TFY_URL, \"mlfoundry\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(epoch=100, lr=0.2, hidden=15, run=run, seed=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "y_true = y_test.detach().numpy()\n",
    "y_true = np.reshape(y_true, y_true.shape[0])\n",
    "y_pred = net(X_test).detach().numpy()\n",
    "y_pred = np.reshape(y_pred, y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Test Dataset Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test.detach().numpy(), columns=['0'])\n",
    "X_test_df['targets'] = y_true\n",
    "X_test_df['predictions'] = y_pred\n",
    "\n",
    "# shap value computation\n",
    "shap_values = shap.DeepExplainer(net, X)\n",
    "shap_values = shap_values.shap_values(X_test)\n",
    "\n",
    "run.log_dataset_stats(\n",
    "    X_test_df, \n",
    "    data_slice='test',\n",
    "    data_schema=mlf.Schema(\n",
    "        feature_column_names=['0'],\n",
    "        prediction_column_name='predictions',\n",
    "        actual_column_name='targets'\n",
    "    ),\n",
    "    shap_values=shap_values,\n",
    "    model_type='regression',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.end()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32eca55f60ca0a4eb05caeb15f62cadd2ce358ded6aecd1922b0adda9a0225d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
