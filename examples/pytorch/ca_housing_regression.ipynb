{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d21accf-3e57-4b52-ae51-4b629b81038c",
   "metadata": {},
   "source": [
    "# Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/examples/pytorch/ca_housing_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88064d5-84e9-471d-b482-fdfc611d9d1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install dependencies\n",
    "\n",
    "For torch, it is recommended to follow the instructions at https://pytorch.org/get-started/locally/  \n",
    "We will use the one already installed, otherwise we will just install the CPU version for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69e263-4b1f-40d1-ae6b-60b79d5bc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet \"numpy>=1.0.0,<2.0.0\" \"pandas>=1.0.0,<2.0.0\" scikit-learn shap==0.40.0\n",
    "! pip install --quiet \"torch>=1.2.0,<2.0.0\"\n",
    "! pip install -U \"mlfoundry>=0.4.6,<0.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed21443-05fd-4e90-91dd-ee92309acec3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize MLFoundry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005e0b9-593f-4aae-8ff3-747144f7a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384565b-21fa-4ad7-a855-be0832adebde",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38df2b0-0f81-4cd8-ab6d-b7b725563f11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## California Housing Price Prediction as a Regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836e4c4-66ff-4d49-b2b2-96ffbcc1a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import urllib.parse\n",
    "import random\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "import json\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f9f68-71df-43a4-aa90-b563d67624ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the California Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb89055-39e5-4a04-8bbb-898acd84c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_california_housing(as_frame=True)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2f2b4-728c-43b3-9dc1-aa47283df0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb6b53-d5aa-4efb-bf75-22cebc8cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16b4d5-383e-4a5c-8a1d-860931dd166e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define the model and dataset utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02e360-04f9-400d-ae6c-7553ed8cb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fcb82d-dac6-4930-8943-cbe08f4b7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed_value: int, cuda: bool = False):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def make_dataset(X: pd.DataFrame, y: pd.DataFrame):\n",
    "    dataset = TensorDataset(\n",
    "        torch.from_numpy(X.values.astype(np.float32)),\n",
    "        torch.from_numpy(y.values.astype(np.float32))\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "    \n",
    "def make_dataloader(dataset, batch_size, random_sampler=False):\n",
    "    if random_sampler:\n",
    "        sampler = RandomSampler(dataset)\n",
    "    else:\n",
    "        sampler = None\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        sampler=sampler,\n",
    "        num_workers=1,\n",
    "        collate_fn=None,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        timeout=0,\n",
    "        worker_init_fn=None\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n",
    "    \"\"\"\n",
    "    Taken from huggingface/transformers\n",
    "    \"\"\"\n",
    "    def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "\n",
    "def get_optimizer_and_scheduler(model, learning_rate, total_steps, warmup_ratio, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    warmup_steps = math.ceil(total_steps * warmup_ratio)\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'weight_decay': weight_decay,\n",
    "        },\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'weight_decay': 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddf962-5feb-43b9-9430-443e395d44ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define evaluation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6714ff-b4cf-44aa-b725-0354ceeaaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(model, device, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for (batch_input, batch_target) in dataloader:\n",
    "        batch_input = batch_input.to(device)\n",
    "        _y_true = batch_target.cpu().numpy()\n",
    "        predicted = model(batch_input)\n",
    "        _y_pred = predicted.detach().cpu().numpy()\n",
    "        \n",
    "        y_true.append(_y_true)\n",
    "        y_pred.append(_y_pred)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return {\n",
    "        f'mae': mean_absolute_error(y_true=y_true, y_pred=y_pred),\n",
    "        f'mse': mean_squared_error(y_true=y_true, y_pred=y_pred),\n",
    "        f'r2': r2_score(y_true=y_true, y_pred=y_pred),\n",
    "    }\n",
    "\n",
    "       \n",
    "def predict_on_dataframe(model, device, X_df, batch_size=64):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    y_pred = []\n",
    "    arr = X_df.values.astype(np.float32)\n",
    "    for i in range(0, len(X_df), batch_size):\n",
    "        batch_input = torch.from_numpy(arr[i:i + batch_size])\n",
    "        batch_input = batch_input.to(device)\n",
    "        predicted = model(batch_input)\n",
    "        _y_pred = predicted.detach().cpu().numpy()\n",
    "        y_pred.append(_y_pred)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1efbfb-24ab-4c73-8cd9-4cb478cb0244",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Finally the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893ff2c-3f01-4c24-8524-2d47e05e369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    run,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    device,\n",
    "    hidden_size=100,\n",
    "    learning_rate=0.01,\n",
    "    batch_size=64, \n",
    "    epochs=1,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.001,\n",
    "    seed=2022\n",
    "):\n",
    "    train_dataset = make_dataset(X=X_train, y=y_train)\n",
    "    val_dataset = make_dataset(X=X_val, y=y_val)    \n",
    "    # Create train and validation splits\n",
    "    train_dataloader = make_dataloader(train_dataset, batch_size=batch_size, random_sampler=True)\n",
    "    val_dataloader = make_dataloader(val_dataset, batch_size=batch_size, random_sampler=False)\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "    model = DNN(input_size=input_size, hidden_size=hidden_size, output_size=1)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    total_steps = epochs * len(train_dataloader)\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(\n",
    "        model=model, \n",
    "        learning_rate=learning_rate, \n",
    "        total_steps=total_steps, \n",
    "        warmup_ratio=warmup_ratio, \n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    run.log_params({\n",
    "        'input_size': input_size,\n",
    "        'hidden_size': hidden_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'total_steps': total_steps,\n",
    "        'epochs': epochs,\n",
    "        'warmup_ratio': warmup_ratio,\n",
    "        'seed': seed,\n",
    "        'num_train_samples': len(train_dataset),\n",
    "        'num_validation_samples': len(val_dataset),\n",
    "    })\n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_start_time = timer()\n",
    "        epoch_loss = torch.tensor(0.0).to(device)\n",
    "        for _step, (batch_input, batch_target) in enumerate(train_dataloader):\n",
    "            batch_input = batch_input.to(device)\n",
    "            batch_target = batch_target.to(device)\n",
    "            batch_predicted = model(batch_input)\n",
    "            loss = criterion(batch_predicted, batch_target)        \n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "            step_metrics = {\n",
    "                'step/lr': scheduler.get_last_lr()[0],\n",
    "                'step/train_loss': loss.item(),\n",
    "            }\n",
    "            if global_step % 20 == 0:\n",
    "                print(f'step={global_step}', step_metrics)\n",
    "                run.log_metrics(step_metrics, step=global_step)\n",
    "                \n",
    "        epoch_loss = epoch_loss.item() / len(train_dataloader)\n",
    "        epoch_time = timer() - epoch_start_time\n",
    "\n",
    "        model.eval()\n",
    "        epoch_metrics = {\n",
    "            'epoch/epoch': epoch,\n",
    "            'epoch/lr': scheduler.get_last_lr()[0],\n",
    "            'epoch/train_loss': epoch_loss,\n",
    "            'epoch/time': epoch_time\n",
    "        }\n",
    "        train_metrics = get_eval_metrics(model=model, device=device, dataloader=train_dataloader)\n",
    "        for k, v in train_metrics.items():\n",
    "            epoch_metrics[f'epoch/train_{k}'] = v\n",
    "        val_metrics = get_eval_metrics(model=model, device=device, dataloader=val_dataloader)\n",
    "        for k, v in val_metrics.items():\n",
    "            epoch_metrics[f'epoch/val_{k}'] = v\n",
    "        print(f'epoch={epoch}', epoch_metrics)\n",
    "        run.log_metrics(epoch_metrics, step=global_step)\n",
    "        \n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfd684-6790-41c8-9a46-c2ca1aae7b8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start a MLFoundry Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196efb8-ff87-4f85-a506-fd40824749fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = client.create_run(project_name='pytorch-ca-housing-example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828ae0f-3ac1-4c7a-a5f7-ed49a4ea777b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set tags for our run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230ef01-3017-4b3b-a1e0-ae2923ab0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "run.set_tags({'framework': 'pytorch', 'use_gpu': use_gpu, 'task': 'regression'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7731ace-c38f-40dc-99d4-41c482772173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split Dataset into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935ab08-9003-4762-81bc-a1a95c4c775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2f530-3679-4d1e-85ca-cb028ecb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "set_random_seed(SEED, cuda=use_gpu)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=SEED)\n",
    "feature_columns = X_train.columns.tolist()\n",
    "X_train = X_train[feature_columns]\n",
    "X_val = X_val[feature_columns]\n",
    "\n",
    "print('Feature columns:', feature_columns)\n",
    "print('Train samples:', len(X_train))\n",
    "print('Validation samples:', len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af980f-23e2-48a8-875c-a46830b4131c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5207c18-e1e3-4570-9736-5ecd9a23881e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "device = torch.device('cuda') if use_gpu else torch.device('cpu')\n",
    "model, optimizer, scheduler = train(\n",
    "    run=run,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    device=device,\n",
    "    hidden_size=128,\n",
    "    learning_rate=0.005,\n",
    "    batch_size=128, \n",
    "    epochs=EPOCHS,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.001,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499894f-7458-4041-be4b-f3c7dd2066c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save and Log model, optimizer and feature column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783cbc97-73b1-4786-a830-f8e304dba9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'epochs-{EPOCHS}'\n",
    "json.dump(feature_columns, open(f'{fname}.features.json', 'w'))\n",
    "torch.save(model, f'{fname}.model.pth')\n",
    "torch.save(optimizer, f'{fname}.optim.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40248027-1735-4f13-9efb-317c5aa7175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_model(\n",
    "    name=\"california-housing-regressor\",\n",
    "    model=model, \n",
    "    framework=mlf.ModelFramework.PYTORCH,\n",
    "    description=f\"pytorch model trained for {EPOCHS} epochs\" \n",
    ")\n",
    "run.log_artifact(f'{fname}.optim.pth')\n",
    "run.log_artifact(f'{fname}.features.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2209ffb-8fef-47fe-a16a-202b4dc6657f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute predictions and log train dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fabd79-2922-4b9e-8203-887de6164b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train.copy()\n",
    "train_df['targets'] = y_train.values\n",
    "train_df['predictions'] = predict_on_dataframe(model, device, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9bcd1-e226-42fe-888d-5ba48a9471b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a5294-e5f2-4a6d-b6db-ec0db7bf5ac8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eac6f9-9416-4a31-a105-5ba707d98bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='train',\n",
    "    features=X_train,\n",
    "    predictions=train_df['predictions'],\n",
    "    actuals=train_df['targets'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198725b-0646-4594-b231-fc5432eb1bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da899f-cb19-4d70-a657-0703c31063d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = X_val.copy()\n",
    "val_df['targets'] = y_val.values\n",
    "val_df['predictions'] = predict_on_dataframe(model, device, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34932b74-11b2-4f0e-b795-2110b19c591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df438a-9989-4dd5-9f2b-5737c087269c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3f5dd-5484-4bb9-94cb-9397830d7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='validation',\n",
    "    features=X_val,\n",
    "    predictions=val_df['predictions'],\n",
    "    actuals=val_df['targets'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6596f1-47be-4e62-8bb5-f83a326ba29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
