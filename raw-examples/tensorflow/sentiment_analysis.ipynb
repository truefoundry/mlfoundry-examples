{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/raw-examples/tensorflow/sentiment_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLk6vtjCzYQy",
    "tags": []
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkR4CLCvzYQz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"numpy>=1.0.0,<2.0.0\" \"pandas>=1.0.0,<2.0.0\" \"matplotlib>=3.5.2,<3.6.0\" \"tensorflow>=2.0.0,<3.0.0\" shap==0.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrWIFkbyzYQ2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kHD7ltDzYQ3"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oy_duiRzYQ4"
   },
   "source": [
    "### Building the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQ4BJqKszYQ4"
   },
   "outputs": [],
   "source": [
    "# To remove <br/> from input text\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "embedding_dim = 16\n",
    "epochs = 10\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    remove_dir = os.path.join(train_dir, 'unsup')\n",
    "    shutil.rmtree(remove_dir)\n",
    "\n",
    "\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "class MetricsLogCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_raw_dataset():\n",
    "    raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'aclImdb/train',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=seed)\n",
    "\n",
    "    raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'aclImdb/train',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=seed)\n",
    "\n",
    "    raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'aclImdb/test',\n",
    "        batch_size=batch_size)\n",
    "    return raw_train_ds, raw_val_ds, raw_test_ds\n",
    "\n",
    "\n",
    "def prep_dataset(raw_train_ds, raw_val_ds, raw_test_ds):\n",
    "    # Make a text-only dataset (without labels), then call adapt\n",
    "    train_text = raw_train_ds.map(lambda x, y: x)\n",
    "    vectorize_layer.adapt(train_text)\n",
    "\n",
    "    # retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "    text_batch, label_batch = next(iter(raw_train_ds))\n",
    "\n",
    "    train_ds = raw_train_ds.map(vectorize_text)\n",
    "    val_ds = raw_val_ds.map(vectorize_text)\n",
    "    test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def build_model(train_ds, val_ds, test_ds):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Embedding(max_features + 1, embedding_dim),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer='adam',\n",
    "                  metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=[MetricsLogCallback()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_exportable_model(model):\n",
    "    export_model = tf.keras.Sequential([\n",
    "        vectorize_layer,\n",
    "        model,\n",
    "        layers.Activation('sigmoid')\n",
    "    ])\n",
    "\n",
    "    export_model.compile(\n",
    "        loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    "    )\n",
    "    return export_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bE_UbKYqzYQ5"
   },
   "outputs": [],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxJqKqqRzYQ6"
   },
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vwu2jaDczYQ6"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_train_ds, raw_val_ds, raw_test_ds = get_raw_dataset()\n",
    "train_ds, val_ds, test_ds = prep_dataset(raw_train_ds, raw_val_ds, raw_test_ds)\n",
    "model = build_model(train_ds, val_ds, test_ds)\n",
    "export_model = build_exportable_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2_N2fzzzYQ7"
   },
   "source": [
    "### Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33uOrbSMzYQ7"
   },
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_test_ds.take(1):\n",
    "    X_test = text_batch.numpy()\n",
    "    y_test = label_batch.numpy()\n",
    "\n",
    "y_hat_test = export_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z24WsVMyzYQ7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment_analysis.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "28092292923bed62c8b687b499027e8fe5fa2d6eed1f342433a13f18841f982d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
